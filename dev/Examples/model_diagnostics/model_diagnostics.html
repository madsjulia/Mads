<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Model Diagnostics · Mads</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://madsjulia.github.io/Mads.jl/Examples/model_diagnostics/model_diagnostics.html"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../index.html"><img src="../../assets/logo.png" alt="Mads logo"/></a><form class="docs-search" action="../../search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../index.html">MADS</a></li><li><a class="tocitem" href="../../Getting_Started.html">Getting Started</a></li><li><a class="tocitem" href="../Examples.html">Example Problems</a></li><li class="is-active"><a class="tocitem" href="model_diagnostics.html">Model Diagnostics</a><ul class="internal"><li><a class="tocitem" href="#Problem-setup"><span>Problem setup</span></a></li><li><a class="tocitem" href="#Forward-model-simulation"><span>Forward model simulation</span></a></li><li><a class="tocitem" href="#Model-calibration"><span>Model calibration</span></a></li><li><a class="tocitem" href="#Model-calibration-with-random-initial-guesses"><span>Model calibration with random initial guesses</span></a></li><li><a class="tocitem" href="#Sensitivity-and-uncertainty-analyses"><span>Sensitivity and uncertainty analyses</span></a></li><li><a class="tocitem" href="#Global-sensitivity-and-uncertainty-analyses"><span>Global sensitivity and uncertainty analyses</span></a></li><li><a class="tocitem" href="#Decision-Analysis"><span>Decision Analysis</span></a></li></ul></li><li><a class="tocitem" href="../model_inversion_contamination/model_inversion_contamination.html">Model Calibration</a></li><li><a class="tocitem" href="../bayesian_sampling/bayesian_sampling.html">Uncertainty Quantification</a></li><li><a class="tocitem" href="../infogap/infogap.html">Decision Analysis</a></li><li><a class="tocitem" href="../blind_source_separation/blind_source_separation.html">Blind Source Separation</a></li><li><a class="tocitem" href="../contamination/contamination.html">Contaminant Transport</a></li><li><a class="tocitem" href="../contaminant_source_identification/contaminant_source_identification.html">Contaminant Source Identification</a></li><li><a class="tocitem" href="../bigdt/source_termination/source_termination.html">Contaminant Source Remediation</a></li><li><a class="tocitem" href="../ode/ode.html">ODE Analysis</a></li><li><a class="tocitem" href="../../Model_Coupling.html">Model Coupling</a></li><li><a class="tocitem" href="../../Notebooks.html">Notebooks</a></li><li><a class="tocitem" href="../../Modules.html">Modules</a></li><li><a class="tocitem" href="../../Testing.html">Testing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="model_diagnostics.html">Model Diagnostics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="model_diagnostics.html">Model Diagnostics</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/madsjulia/Mads.jl/blob/master/docs/src/Examples/model_diagnostics/model_diagnostics.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Model-diagnostics"><a class="docs-heading-anchor" href="#Model-diagnostics">Model diagnostics</a><a id="Model-diagnostics-1"></a><a class="docs-heading-anchor-permalink" href="#Model-diagnostics" title="Permalink"></a></h1><p><a href="http://madsjulia.github.io/Mads.jl">MADS</a> is applied to solve a general model diagnostic problem.</p><p>By performing model diagnostics, we want to better understand:</p><ul><li>how the model inputs impact model outputs?</li><li>how observed data related to the model outputs can be applied to learn more about the model inputs?</li></ul><p>A Jupyter notebook of this problem is also available (<a href="https://github.com/madsjulia/Mads.jl/blob/master/notebooks/model_diagnostics/model_diagnostics.ipynb">Jupyter</a>)</p><h2 id="Problem-setup"><a class="docs-heading-anchor" href="#Problem-setup">Problem setup</a><a id="Problem-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Problem-setup" title="Permalink"></a></h2><h3 id="Setup-the-model:"><a class="docs-heading-anchor" href="#Setup-the-model:">Setup the model:</a><a id="Setup-the-model:-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-the-model:" title="Permalink"></a></h3><p>A function (called <code>polynomial</code>) is defined to compute the 6 observations given the 4 model parameters as an input:</p><pre><code class="language-julia hljs">function polynomial(parameters::AbstractVector)
	f(t) = parameters[1] * (t ^ parameters[4]) + parameters[2] * t + parameters[3] # a * t^n + b * t + c
	predictions = map(f, 0:5)
	return predictions
end</code></pre><p>This function will be applied in the model diagnostics analyses presented below.</p><p>Much more complicated functions including external numerical simulators can be applied as well. Checkout <a href="../../Model_Coupling.html">Model Coupling</a></p><h3 id="Setup-the-problem-dictionary-(method-#1)"><a class="docs-heading-anchor" href="#Setup-the-problem-dictionary-(method-#1)">Setup the problem dictionary (method #1)</a><a id="Setup-the-problem-dictionary-(method-#1)-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-the-problem-dictionary-(method-#1)" title="Permalink"></a></h3><p>A problem dictionary is applied to store all the information related to the analyzed problem.</p><p>The problem dictionary with this information is created as follows:</p><pre><code class="language-julia hljs">md = Mads.createproblem([1, 1, 1, 1], # parameter initial guesses
		[0, 1.1, 1.9, 3.1, 3.9, 5], # observations
		polynomial; # function call to execute the model
		paramkey=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;n&quot;], # parameter names
		paramdist=[&quot;Uniform(-10, 10)&quot;, &quot;Uniform(-10, 10)&quot;, &quot;Uniform(-5, 5)&quot;, &quot;Uniform(0, 3)&quot;], # parameter uncertainties
		obsweight=[100, 100, 100, 100, 10, 0], # observation weights
		obstime=[0, 1, 2, 3, 4, 5], # observation times
		obsdist=[&quot;Uniform(0, 1)&quot;, &quot;Uniform(0, 2)&quot;, &quot;Uniform(1, 3)&quot;, &quot;Uniform(2, 4)&quot;, &quot;Uniform(3, 5)&quot;, &quot;Uniform(4, 6)&quot;], # observation uncertainties
		problemname=&quot;model_diagnostics&quot; # Problem name
)</code></pre><pre><code class="nohighlight hljs">Dict{Any, Any} with 4 entries:
  &quot;Julia function&quot; =&gt; polynomial
  &quot;Parameters&quot;     =&gt; OrderedCollections.OrderedDict{Any, Any}(&quot;a&quot;=&gt;OrderedColl…
  &quot;Observations&quot;   =&gt; OrderedCollections.OrderedDict{Any, Any}(&quot;o1&quot;=&gt;OrderedCol…
  &quot;Filename&quot;       =&gt; &quot;model_diagnostics.mads&quot;</code></pre><p>The problem dictionary includes information about:</p><ul><li>parameter names (<code>[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;n&quot;]</code>)</li><li>parameter initial guesses (<code>[1, 1, 1, 1]</code>)</li><li>parameter prior distributions (<code>[&quot;Uniform(-10, 10)&quot;, &quot;Uniform(-10, 10)&quot;, &quot;Uniform(-5, 5)&quot;, &quot;Uniform(0, 3)&quot;]</code>, i.e., prior parameter uncertainties)</li><li>true observation values that we want to reproduce (<code>[0, 1.1, 1.9 3.1, 3.9 ,5]</code>)</li><li>observation distributions (i.e., uncertainty ranges or measurement errors)</li><li>observation weights (<code>[100, 100, 100, 100, 10, 0]</code>; the higher the weight; the higher the observation importance)</li><li>observation times (<code>[0, 1, 2, 3, 4, 5]</code>) at which observations are made</li></ul><p>The 6 observations are automatically labelled as (<code>o1</code>, <code>o2</code>, <code>o3</code>, <code>o4</code>, <code>o5</code> and <code>o6</code>).</p><p>The observations are values that we want to reproduce with our model.</p><p>They can be also called calibration targets.</p><p>For each observation (calibration target), we specify observation weight (i.e., the inverse of measurement standard deviations).</p><p>Zero observation weight implies that the observation is unknown (potentially occuring in the future) and will be estimated (predicted) by the developed model.</p><p>Acceptable ranges are defined for each observation representing observation uncertainties.</p><h3 id="Setup-the-problem-dictionary-(method-#2)"><a class="docs-heading-anchor" href="#Setup-the-problem-dictionary-(method-#2)">Setup the problem dictionary (method #2)</a><a id="Setup-the-problem-dictionary-(method-#2)-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-the-problem-dictionary-(method-#2)" title="Permalink"></a></h3><p>The same problem dictionary can be created in a step-by-step fashion which is slightly more explicit.</p><h4 id="Setup-empty-dictionary:"><a class="docs-heading-anchor" href="#Setup-empty-dictionary:">Setup empty dictionary:</a><a id="Setup-empty-dictionary:-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-empty-dictionary:" title="Permalink"></a></h4><pre><code class="language-julia hljs">md = Dict()</code></pre><h4 id="Setup-model-parameters:"><a class="docs-heading-anchor" href="#Setup-model-parameters:">Setup model parameters:</a><a id="Setup-model-parameters:-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-model-parameters:" title="Permalink"></a></h4><pre><code class="language-julia hljs">md[&quot;Parameters&quot;], _, _ = Mads.createparameters([1, 1, 1, 1];
	key=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;n&quot;],
	dist=[&quot;Uniform(-10, 10)&quot;, &quot;Uniform(-10, 10)&quot;, &quot;Uniform(-5, 5)&quot;, &quot;Uniform(0, 3)&quot;])</code></pre><pre><code class="nohighlight hljs">OrderedCollections.OrderedDict{Any, Any} with 4 entries:
  &quot;a&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;init&quot;=&gt;1, &quot;type&quot;=&gt;&quot;opt&quot;, …
  &quot;b&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;init&quot;=&gt;1, &quot;type&quot;=&gt;&quot;opt&quot;, …
  &quot;c&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;init&quot;=&gt;1, &quot;type&quot;=&gt;&quot;opt&quot;, …
  &quot;n&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;init&quot;=&gt;1, &quot;type&quot;=&gt;&quot;opt&quot;, …</code></pre><p>There are 4 model parameters (<code>a</code>, <code>b</code>, <code>c</code>, and <code>n</code>).</p><p>The initial values and the prior distributions (based on prior knowledge of the parameter uncertainty) are defined for each parameter.</p><h4 id="Setup-model-observations:"><a class="docs-heading-anchor" href="#Setup-model-observations:">Setup model observations:</a><a id="Setup-model-observations:-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-model-observations:" title="Permalink"></a></h4><pre><code class="language-julia hljs">md[&quot;Observations&quot;] = Mads.createobservations([0, 1.1, 1.9, 3.1, 3.9 ,5];
	weight=[100, 100, 100, 100, 10, 0],
	time=[0, 1, 2, 3, 4, 5],
	dist=[&quot;Uniform(0, 1)&quot;, &quot;Uniform(0, 2)&quot;, &quot;Uniform(1, 3)&quot;, &quot;Uniform(2, 4)&quot;, &quot;Uniform(3, 5)&quot;, &quot;Uniform(4, 6)&quot;])</code></pre><pre><code class="nohighlight hljs">OrderedCollections.OrderedDict{Any, Any} with 6 entries:
  &quot;o1&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;target&quot;=&gt;0.0, &quot;weight&quot;=&gt;…
  &quot;o2&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;target&quot;=&gt;1.1, &quot;weight&quot;=&gt;…
  &quot;o3&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;target&quot;=&gt;1.9, &quot;weight&quot;=&gt;…
  &quot;o4&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;target&quot;=&gt;3.1, &quot;weight&quot;=&gt;…
  &quot;o5&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;target&quot;=&gt;3.9, &quot;weight&quot;=&gt;…
  &quot;o6&quot; =&gt; OrderedCollections.OrderedDict{String, Any}(&quot;target&quot;=&gt;5.0, &quot;weight&quot;=&gt;…</code></pre><h4 id="Setup-the-model"><a class="docs-heading-anchor" href="#Setup-the-model">Setup the model</a><a id="Setup-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Setup-the-model" title="Permalink"></a></h4><p>The <code>polynomial</code> function is set up now in the <code>md</code> dictionary as a model that will be applied to perform the simulations:</p><pre><code class="language-julia hljs">Mads.setmodel!(md, polynomial)</code></pre><p>The analyzed model captured in the problem dictionary can be:</p><ul><li>analytical or numerical</li><li>internal or external (e.g., PFLOTRAN, FEHM, or any other simulator)</li></ul><p>The model can also be a reduced-order model developed using machine learning.</p><h4 id="Set-a-default-name-for-MADS-input-/-output-files:"><a class="docs-heading-anchor" href="#Set-a-default-name-for-MADS-input-/-output-files:">Set a default name for MADS input / output files:</a><a id="Set-a-default-name-for-MADS-input-/-output-files:-1"></a><a class="docs-heading-anchor-permalink" href="#Set-a-default-name-for-MADS-input-/-output-files:" title="Permalink"></a></h4><pre><code class="language-julia hljs">md[&quot;Filename&quot;] = &quot;model_diagnostics.mads&quot;</code></pre><p>Now, the problem dictionary <code>md</code> is fully defined:</p><pre><code class="language-julia hljs">display(md)</code></pre><pre><code class="nohighlight hljs">Dict{Any, Any} with 4 entries:
  &quot;Julia function&quot; =&gt; polynomial
  &quot;Parameters&quot;     =&gt; OrderedCollections.OrderedDict{Any, Any}(&quot;a&quot;=&gt;OrderedColl…
  &quot;Observations&quot;   =&gt; OrderedCollections.OrderedDict{Any, Any}(&quot;o1&quot;=&gt;OrderedCol…
  &quot;Filename&quot;       =&gt; &quot;model_diagnostics.mads&quot;</code></pre><p>And the model diagnostic problem is set up!</p><p>We can also double check the problem setup.</p><pre><code class="language-julia hljs">Mads.showparameters(md)</code></pre><pre><code class="nohighlight hljs">a =               1 distribution = Uniform(-10, 10)
b =               1 distribution = Uniform(-10, 10)
c =               1 distribution = Uniform(-5, 5)
n =               1 distribution = Uniform(0, 3)
Number of optimizable parameters: 4</code></pre><pre><code class="language-julia hljs">Mads.showobservations(md)</code></pre><pre><code class="nohighlight hljs">o1         target =               0 weight =             100
o2         target =             1.1 weight =             100
o3         target =             1.9 weight =             100
o4         target =             3.1 weight =             100
o5         target =             3.9 weight =              10
o6         target =               5 weight =               0
Number of observations is 6</code></pre><h2 id="Forward-model-simulation"><a class="docs-heading-anchor" href="#Forward-model-simulation">Forward model simulation</a><a id="Forward-model-simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-model-simulation" title="Permalink"></a></h2><p>A single forward model run based on the initial model parameter values can be executed as follows:</p><pre><code class="language-julia hljs">Mads.forward(md)</code></pre><pre><code class="nohighlight hljs">OrderedCollections.OrderedDict{Any, Float64} with 6 entries:
  &quot;o1&quot; =&gt; 1.0
  &quot;o2&quot; =&gt; 3.0
  &quot;o3&quot; =&gt; 5.0
  &quot;o4&quot; =&gt; 7.0
  &quot;o5&quot; =&gt; 9.0
  &quot;o6&quot; =&gt; 11.0</code></pre><p>The forward model run can also be executed using the following command:</p><pre><code class="language-julia hljs">polynomial(Mads.getparamsinit(md))</code></pre><pre><code class="nohighlight hljs">6-element Vector{Float64}:
  1.0
  3.0
  5.0
  7.0
  9.0
 11.0</code></pre><p>The runs above produce outputs representing model predictions at the six observations over time.</p><p>The forward simulations are based on the initial guesses for the model parameters.</p><p>The initial model predictions look like this:</p><pre><code class="language-julia hljs">Mads.plotmatches(md)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_33_0.png" alt="png"/></p><p>The figure above shows that the <code>true</code> observations are not well reproduced by the model using the initial model parameter guesses.</p><h2 id="Model-calibration"><a class="docs-heading-anchor" href="#Model-calibration">Model calibration</a><a id="Model-calibration-1"></a><a class="docs-heading-anchor-permalink" href="#Model-calibration" title="Permalink"></a></h2><p>The calibration (inversion) of the developed model is achieved using the following command:</p><pre><code class="language-julia hljs">calib_param, calib_information = Mads.calibrate(md)</code></pre><p>The code returns 2 objects.</p><ul><li><code>calib_param</code> is a dictionary of the calibrated model parameters.</li><li><code>calib_information</code> contains calibration information.</li></ul><p>The obtained model predictions can be plotted:</p><pre><code class="language-julia hljs">Mads.plotmatches(md, calib_param)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_39_0.png" alt="png"/></p><p>Initial values of the model parameters are:</p><pre><code class="language-julia hljs">Mads.showparameterestimates(md)</code></pre><pre><code class="nohighlight hljs">a =               1 distribution = Uniform(-10, 10)
b =               1 distribution = Uniform(-10, 10)
c =               1 distribution = Uniform(-5, 5)
n =               1 distribution = Uniform(0, 3)
Number of optimizable parameters: 4</code></pre><p>Estimated values of the model parameters based on the model calibration (inversion) are:</p><pre><code class="language-julia hljs">Mads.showparameterestimates(md, calib_param)</code></pre><pre><code class="nohighlight hljs">a =      0.00705046 distribution = Uniform(-10, 10)
b =         0.95069 distribution = Uniform(-10, 10)
c =       0.0385415 distribution = Uniform(-5, 5)
n =         2.93219 distribution = Uniform(0, 3)
Number of optimizable parameters: 4</code></pre><h2 id="Model-calibration-with-random-initial-guesses"><a class="docs-heading-anchor" href="#Model-calibration-with-random-initial-guesses">Model calibration with random initial guesses</a><a id="Model-calibration-with-random-initial-guesses-1"></a><a class="docs-heading-anchor-permalink" href="#Model-calibration-with-random-initial-guesses" title="Permalink"></a></h2><p>The model inversion can also be performed for a set of random initial guesses for model parameters.</p><pre><code class="language-julia hljs">calib_random_results = Mads.calibraterandom(md, 100; seed=2021, all=true)</code></pre><pre><code class="nohighlight hljs">100×3 Matrix{Any}:
  232.272  …  OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.00653517, &quot;b&quot;=&gt;0.950689, &quot;c&quot;=&gt;0.039249, &quot;n&quot;=&gt;3.0)
  270.314     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-0.28542, &quot;b&quot;=&gt;1.27948, &quot;c&quot;=&gt;0.0178456, &quot;n&quot;=&gt;0.951994)
  232.272     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.00653398, &quot;b&quot;=&gt;0.950704, &quot;c&quot;=&gt;0.0392286, &quot;n&quot;=&gt;3.0)
  232.272     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.00653436, &quot;b&quot;=&gt;0.950702, &quot;c&quot;=&gt;0.0392321, &quot;n&quot;=&gt;2.99998)
  232.272     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.00653522, &quot;b&quot;=&gt;0.950689, &quot;c&quot;=&gt;0.039249, &quot;n&quot;=&gt;3.0)
  270.097  …  OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-4.30065, &quot;b&quot;=&gt;5.28695, &quot;c&quot;=&gt;0.0214167, &quot;n&quot;=&gt;0.995285)
 7643.02      OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-9.89624, &quot;b&quot;=&gt;9.82224, &quot;c&quot;=&gt;0.622939, &quot;n&quot;=&gt;0.910639)
  269.91      OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-4.41759, &quot;b&quot;=&gt;5.40692, &quot;c&quot;=&gt;0.0206894, &quot;n&quot;=&gt;0.9961)
  270.093     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-4.82082, &quot;b&quot;=&gt;5.80708, &quot;c&quot;=&gt;0.0214349, &quot;n&quot;=&gt;0.995788)
  270.067     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-2.58655, &quot;b&quot;=&gt;3.57364, &quot;c&quot;=&gt;0.0211371, &quot;n&quot;=&gt;0.992455)
    ⋮      ⋱
  270.091     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-5.97129, &quot;b&quot;=&gt;6.95745, &quot;c&quot;=&gt;0.0214664, &quot;n&quot;=&gt;0.996586)
  270.122     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-2.481, &quot;b&quot;=&gt;3.46755, &quot;c&quot;=&gt;0.0212952, &quot;n&quot;=&gt;0.991901)
  269.794     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;3.95245, &quot;b&quot;=&gt;-2.96176, &quot;c&quot;=&gt;0.0197838, &quot;n&quot;=&gt;1.00408)
  232.272     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.00653517, &quot;b&quot;=&gt;0.950689, &quot;c&quot;=&gt;0.039249, &quot;n&quot;=&gt;3.0)
  232.272  …  OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.00653516, &quot;b&quot;=&gt;0.950689, &quot;c&quot;=&gt;0.0392491, &quot;n&quot;=&gt;3.0)
  270.802     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-0.121823, &quot;b&quot;=&gt;1.11748, &quot;c&quot;=&gt;0.0170054, &quot;n&quot;=&gt;0.896066)
  269.868     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;0.962624, &quot;b&quot;=&gt;0.0219806, &quot;c&quot;=&gt;0.0223074, &quot;n&quot;=&gt;1.02225)
  270.09      OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-5.46149, &quot;b&quot;=&gt;6.44768, &quot;c&quot;=&gt;0.0214512, &quot;n&quot;=&gt;0.996277)
  270.362     OrderedCollections.OrderedDict(&quot;a&quot;=&gt;-0.387051, &quot;b&quot;=&gt;1.37691, &quot;c&quot;=&gt;0.0197667, &quot;n&quot;=&gt;0.954846)</code></pre><p>The final parameter estimates from the 100 random-initial-guess inverse runs are collected into a matrix below:</p><pre><code class="language-julia hljs">calib_random_estimates = hcat(map(i-&gt;collect(values(calib_random_results[i,3])), 1:100)...)</code></pre><pre><code class="nohighlight hljs">4×100 Matrix{Float64}:
 0.00653517  -0.28542    0.00653398  …  0.962624   -5.46149    -0.387051
 0.950689     1.27948    0.950704       0.0219806   6.44768     1.37691
 0.039249     0.0178456  0.0392286      0.0223074   0.0214512   0.0197667
 3.0          0.951994   3.0            1.02225     0.996277    0.954846</code></pre><p>Plot the final predictions of the 100 random-initial-guess inverse runs:</p><pre><code class="language-julia hljs">forward_predictions = Mads.forward(md, calib_random_estimates)
Mads.spaghettiplot(md, forward_predictions)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_49_0.png" alt="png"/></p><p>The results and figure above demonstrate that there are several different &quot;global&quot; minima.</p><p>There are three important groups of results with different <code>n</code> values:</p><ul><li><code>n</code> = 0</li><li><code>n</code> = 1</li><li><code>n</code> = 3 (capturing the upper prior bound)</li></ul><p>The code below identifies and plots solutions associated with these 3 distinct groups:</p><pre><code class="language-julia hljs">ind_n0 = abs.(calib_random_estimates[4,:]) .&lt; 0.1
in0 = findall(ind_n0 .== true)[1]
ind_n1 = abs.(calib_random_estimates[4,:] .- 1) .&lt; 0.1
in1 = findall(ind_n1 .== true)[1]
ind_n3 = .!(ind_n0 .| ind_n1)
in3 = findall(ind_n3 .== true)[1]
pinit = Dict(zip(Mads.getparamkeys(md), Mads.getparamsinit(md)))
optnames = [&quot;n=0&quot;, &quot;n=1&quot;, &quot;n=3&quot;]
v = [in0, in1, in3]

for i = 1:3
	println(&quot;Solution for $(optnames[i])&quot;)
	Mads.showparameters(md, calib_random_results[v[i],3])
	Mads.plotmatches(md, calib_random_results[v[i],3]; title=optnames[i])
end</code></pre><p><img src="model_diagnostics_files/model_diagnostics_51_0.png" alt="png"/></p><pre><code class="nohighlight hljs">Solution for n=0
a =       0.0354613 distribution = Uniform(-10, 10)
b =        0.998702 distribution = Uniform(-10, 10)
c =     1.70238e-05 distribution = Uniform(-5, 5)
n =     0.000376271 distribution = Uniform(0, 3)
Number of optimizable parameters: 4</code></pre><p><img src="model_diagnostics_files/model_diagnostics_51_2.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_51_3.png" alt="png"/></p><pre><code class="nohighlight hljs">Solution for n=1
a =        -0.28542 distribution = Uniform(-10, 10)
b =         1.27948 distribution = Uniform(-10, 10)
c =       0.0178456 distribution = Uniform(-5, 5)
n =        0.951994 distribution = Uniform(0, 3)
Number of optimizable parameters: 4
Solution for n=3
a =      0.00653517 distribution = Uniform(-10, 10)
b =        0.950689 distribution = Uniform(-10, 10)
c =        0.039249 distribution = Uniform(-5, 5)
n =               3 distribution = Uniform(0, 3)
Number of optimizable parameters: 4</code></pre><h2 id="Sensitivity-and-uncertainty-analyses"><a class="docs-heading-anchor" href="#Sensitivity-and-uncertainty-analyses">Sensitivity and uncertainty analyses</a><a id="Sensitivity-and-uncertainty-analyses-1"></a><a class="docs-heading-anchor-permalink" href="#Sensitivity-and-uncertainty-analyses" title="Permalink"></a></h2><h3 id="Local-sensitivity-and-uncertainty-quantification"><a class="docs-heading-anchor" href="#Local-sensitivity-and-uncertainty-quantification">Local sensitivity and uncertainty quantification</a><a id="Local-sensitivity-and-uncertainty-quantification-1"></a><a class="docs-heading-anchor-permalink" href="#Local-sensitivity-and-uncertainty-quantification" title="Permalink"></a></h3><pre><code class="language-julia hljs">localsa = Mads.localsa(md; filename=&quot;model_diagnostics.png&quot;, par=collect(values(calib_param)))</code></pre><pre><code class="nohighlight hljs">Dict{String, Any} with 6 entries:
  &quot;of&quot;          =&gt; 233.373
  &quot;jacobian&quot;    =&gt; [0.0 0.0 498.96 0.0; 998.299 989.063 498.96 0.0; … ; 5815.86…
  &quot;covar&quot;       =&gt; [9.60666e-7 -1.96149e-6 6.59975e-7 -0.00248792; -1.96149e-6 …
  &quot;eigenmatrix&quot; =&gt; [-0.99148 0.126137 0.0324964 0.000380915; -0.128081 -0.89869…
  &quot;eigenvalues&quot; =&gt; [1.36761e-9, 4.44737e-7, 4.31592e-6, 6.53143]
  &quot;stddev&quot;      =&gt; [0.000980135, 0.00217703, 0.00198921, 2.55567]</code></pre><p><code>localsa[&quot;stddev&quot;]</code> defines the estimated posterior uncertainties in the estimated model parameters.</p><p>This estimate is based on the Jacobian / Hessian matrix estimates of the parameter space curvature in the vicinity of the estimated (inverted) optimal parameters.</p><p>The uncertainties are assumed to be Gaussian with standard deviations defined by <code>localsa[&quot;stddev&quot;]</code>.</p><pre><code class="language-julia hljs">[Mads.getparamlabels(md) localsa[&quot;stddev&quot;]]</code></pre><pre><code class="nohighlight hljs">4×2 Matrix{Any}:
 &quot;a&quot;  0.000980135
 &quot;b&quot;  0.00217703
 &quot;c&quot;  0.00198921
 &quot;n&quot;  2.55567</code></pre><p>Based on these results, <code>c</code> is well constrained. <code>n</code> is also well defined. In contrast, <code>a</code> and <code>b</code> are less certain.</p><p>However, because of the local nature of the estimates, these results are not very accurate and differ with the global sensitivity and uncertainty analyses presented below.</p><p>The plots below show a series of graphical representations of the <code>localsa</code> results. These plots are generated automatically by the code.</p><p>A plot of the Jacobian representing the relationships between model parameters and estimated observations:</p><pre><code class="language-julia hljs">Mads.display(&quot;model_diagnostics-jacobian.png&quot;)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_58_0.png" alt="png"/></p><p>A plot of the eigen matrix of the Hessian (the Hessian is approximately computed based on the Jacobian above):</p><pre><code class="language-julia hljs">Mads.display(&quot;model_diagnostics-eigenmatrix.png&quot;)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_60_0.png" alt="png"/></p><p>A plot of the eigen values of the Hessian matrix:</p><pre><code class="language-julia hljs">Mads.display(&quot;model_diagnostics-eigenvalues.png&quot;)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_62_0.png" alt="png"/></p><p>The eigen analysis presented above suggests that <code>a</code> and <code>b</code> are correlated (this is expected based on the mathematical form of the solved model in the function <code>polynomial</code>).</p><p>Both parameters are represented by the first and last (4th) eigen vectors.</p><p>The parameters <code>n</code> and <code>c</code> are uncorrelated and also independent of <code>a</code> and <code>b</code>.</p><h2 id="Global-sensitivity-and-uncertainty-analyses"><a class="docs-heading-anchor" href="#Global-sensitivity-and-uncertainty-analyses">Global sensitivity and uncertainty analyses</a><a id="Global-sensitivity-and-uncertainty-analyses-1"></a><a class="docs-heading-anchor-permalink" href="#Global-sensitivity-and-uncertainty-analyses" title="Permalink"></a></h2><h3 id="Affine-Invariant-MCMC"><a class="docs-heading-anchor" href="#Affine-Invariant-MCMC">Affine Invariant MCMC</a><a id="Affine-Invariant-MCMC-1"></a><a class="docs-heading-anchor-permalink" href="#Affine-Invariant-MCMC" title="Permalink"></a></h3><p>Our module <code>AffineInvariantMCMC.jl</code> (aka <code>EMCEE</code>) is applied to perform global sensitivity and uncertainty quantification:</p><pre><code class="language-julia hljs">chain, llhoods = Mads.emceesampling(md; numwalkers=10, nsteps=100000, burnin=10000, thinning=10, seed=2016, sigma=0.01)</code></pre><p>The results above capture 10,000 equally likely parameter combinations.</p><p>The parameter combintations represent the global sensitivity and uncertainty of the model parameters and associated predictions.</p><p>A forward run based on this set (<code>chain</code>) is executed below:</p><pre><code class="language-julia hljs">f = Mads.forward(md, chain)</code></pre><pre><code class="nohighlight hljs">6×10000 Matrix{Float64}:
 -0.0892523  -0.175495  0.0521224  …  -0.0309209  -0.0293742  0.0285767
  1.04913     0.953271  1.02412        1.00445     1.04269    1.09737
  2.07862     2.03995   2.00473        2.01825     1.99246    2.04729
  3.07556     3.11172   2.98858        3.02342     2.89541    2.95011
  4.05291     4.17404   3.97454        4.02286     3.76782    3.82182
  5.01641     5.22941   4.96206    …   5.01799     4.61745    4.67012</code></pre><pre><code class="language-julia hljs">Mads.spaghettiplot(md, f)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_69_0.png" alt="png"/></p><p>The figure above compares the 10,000 model predictions with the actual measurements (red dots).</p><p>The figure below shows the histograms of the posterior model uncertainties (along the diagonal) and the cross-plots between the parameters (off-diagonal plots; the cross-plots above and below the diagonal are similar):</p><pre><code class="language-julia hljs">Mads.scatterplotsamples(md, permutedims(chain), &quot;model_diagnostics-emcee_scatter.png&quot;)</code></pre><pre><code class="language-julia hljs">Mads.display(&quot;model_diagnostics-emcee_scatter.png&quot;)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_72_0.png" alt="png"/></p><p>The figure above shows that the optimal (most probable) estimates are:</p><ul><li><code>a</code> = 0</li><li><code>b</code> = 1</li><li><code>c</code> = 0</li><li><code>n</code> = 0</li></ul><p><code>c</code> i the most constrained (varying between -0.2 and 0.2).</p><p>There are plausible solutions for any value of <code>a</code>, <code>b</code> and <code>n</code> within the prior uncertainty range.</p><p>The parameters <code>a</code> and <code>b</code> are strongly inversely correlated by their respective cross-plots.</p><p>Based on the cross-plots, the plausible values for <code>n</code> can be within the entire prior uncertainty range if (1) <code>a</code> is equal to 0 and (2) <code>b</code> is equal to 1.</p><p>The plausible values for <code>n</code> are close to 1 if (1) <code>a</code> is very different from 0 and (2) <code>b</code> is very different from 1.</p><h3 id="Saltelli-(Sobol)-and-EFAST-global-sensitivity-analyses"><a class="docs-heading-anchor" href="#Saltelli-(Sobol)-and-EFAST-global-sensitivity-analyses">Saltelli (Sobol) and EFAST global sensitivity analyses</a><a id="Saltelli-(Sobol)-and-EFAST-global-sensitivity-analyses-1"></a><a class="docs-heading-anchor-permalink" href="#Saltelli-(Sobol)-and-EFAST-global-sensitivity-analyses" title="Permalink"></a></h3><p>Both Saltelli (Sobol) and EFAST methods are producing similar results.</p><p>Both methods are designed to perform global sensitivity analyses.</p><p>EFAST is computationally more efficient.</p><p>The Saltelli (Sobol) results are obtained as follows:</p><pre><code class="language-julia hljs">saltelli_results = Mads.saltelli(md, N=10000, seed=2016)</code></pre><pre><code class="nohighlight hljs">Dict{String, Any} with 6 entries:
  &quot;method&quot;     =&gt; &quot;saltelli&quot;
  &quot;samplesize&quot; =&gt; 10000
  &quot;mes&quot;        =&gt; OrderedCollections.OrderedDict(&quot;o1&quot;=&gt;OrderedCollections.Order…
  &quot;tes&quot;        =&gt; OrderedCollections.OrderedDict(&quot;o1&quot;=&gt;OrderedCollections.Order…
  &quot;seed&quot;       =&gt; 2016
  &quot;var&quot;        =&gt; OrderedCollections.OrderedDict(&quot;o1&quot;=&gt;OrderedCollections.Order…</code></pre><pre><code class="language-julia hljs">Mads.plotobsSAresults(md, saltelli_results)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_76_0.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_76_1.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_76_3.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_76_4.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_76_6.png" alt="png"/></p><p>The EFAST results are obtained as follows:</p><pre><code class="language-julia hljs">efastresult = Mads.efast(md, N=1000, seed=2016)
Mads.plotobsSAresults(md, efastresult, filename=&quot;sensitivity_efast.png&quot;, xtitle = &quot;Time [-]&quot;, ytitle = &quot;Observation [-]&quot;)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_78_0.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_78_1.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_78_2.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_78_4.png" alt="png"/></p><p><img src="model_diagnostics_files/model_diagnostics_78_5.png" alt="png"/></p><p>The differences in the <code>total</code> and <code>main</code> effect plots suggest correlations in the model parameters (which is also demonstrated by the <code>AffineInvariantMCMC</code> analyses above).</p><p>The figures also demonstrate that the parameter sensitivity to observations changes over time.</p><p>Based on the <code>total effect</code>, parameter <code>a</code> and <code>n</code> sensitivities generally increase with time. Parameter <code>b</code> and <code>b</code> sensitivities generally decrease with time.</p><h2 id="Decision-Analysis"><a class="docs-heading-anchor" href="#Decision-Analysis">Decision Analysis</a><a id="Decision-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Decision-Analysis" title="Permalink"></a></h2><p>Here, we perform decision Analysis using Information-Gap Decision Theory.</p><p>Define the Information-Gap Decision Theory horizons of uncertainty <code>h</code>:</p><pre><code class="language-julia hljs">h = [0.001, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1]</code></pre><pre><code class="nohighlight hljs">8-element Vector{Float64}:
 0.001
 0.01
 0.02
 0.05
 0.1
 0.2
 0.5
 1.0</code></pre><p>Define the polynomial models to be explored:</p><pre><code class="language-julia hljs">models = [&quot;y = a * t + c&quot;, &quot;y = a * t^(1.1) + b * t + c&quot;, &quot;y = a * t^n + b * t + c&quot;, &quot;y = a * exp(t * n) + b * t + c&quot;]</code></pre><pre><code class="nohighlight hljs">4-element Vector{String}:
 &quot;y = a * t + c&quot;
 &quot;y = a * t^(1.1) + b * t + c&quot;
 &quot;y = a * t^n + b * t + c&quot;
 &quot;y = a * exp(t * n) + b * t + c&quot;</code></pre><p>Execute the infogap analyses, collect the obtained results, and produce a figure summarizing the results:</p><pre><code class="language-julia hljs">import Gadfly
import Colors
lmin = Vector{Any}(undef, 4)
lmax = Vector{Any}(undef, 4)
colors = [&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;, &quot;orange&quot;]
for i = 1:4
	min, max = Mads.infogap_jump_polynomial(model=i, plot=true, horizons=h, retries=10, maxiter=1000, verbosity=0, seed=2015)
	lmin[i] = Gadfly.layer(x=min, y=h, Gadfly.Geom.line, Gadfly.Theme(line_width=2Gadfly.pt, line_style=[:dash], default_color=Base.parse(Colors.Colorant, colors[i])))
	lmax[i] = Gadfly.layer(x=max, y=h, Gadfly.Geom.line, Gadfly.Theme(line_width=2Gadfly.pt, line_style=[:solid], default_color=Base.parse(Colors.Colorant, colors[i])))
end
f = Gadfly.plot(lmin..., lmax..., Gadfly.Guide.xlabel(&quot;o5&quot;), Gadfly.Guide.ylabel(&quot;Horizon of uncertainty&quot;), Gadfly.Guide.title(&quot;Opportuneness vs. Robustness&quot;), Gadfly.Theme(highlight_width=0Gadfly.pt), Gadfly.Guide.manual_color_key(&quot;Models&quot;, models, colors))
Gadfly.draw(Gadfly.PNG(&quot;infogap_opportuneness_vs_robustness.png&quot;, 6Gadfly.inch, 4Gadfly.inch), f)</code></pre><pre><code class="nohighlight hljs">┌ Info: New seed: 2015
└ @ Mads /Users/vvv/.julia/dev/Mads/src/MadsHelpers.jl:462

******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit https://github.com/coin-or/Ipopt
******************************************************************************

Min h = 0.001 OF = 4.998333281688344 par = [0.9993333197989149, 0.0016666826937701167]
Max h = 0.001 OF = 5.00166671833499 par = [1.0006666802044195, -0.001666682687108125]
Min h = 0.01 OF = 4.983333280036714 par = [0.9933333177282005, 0.016666691395710947]
Max h = 0.01 OF = 5.016666718990943 par = [1.0066666807443947, -0.016666684731030848]
Min h = 0.02 OF = 4.966666614342419 par = [0.9866666521256426, 0.033333353714205226]
Max h = 0.02 OF = 5.033333387019943 par = [1.0133333489146892, -0.03333335755350352]
Min h = 0.05 OF = 4.916666615311706 par = [0.9666666528982734, 0.08333335082033852]
Max h = 0.05 OF = 5.08333338580072 par = [1.0333333472115793, -0.08333335025717689]
Min h = 0.1 OF = 4.833333282661476 par = [0.9333333197717608, 0.16666668380267258]
Max h = 0.1 OF = 5.166666719675405 par = [1.0666666805654965, -0.16666668315207778]
Min h = 0.2 OF = 4.666666617013978 par = [0.8666666531305123, 0.333333351361417]
Max h = 0.2 OF = 5.3333333876552285 par = [1.133333347539164, -0.3333333500405913]
Min h = 0.5 OF = 4.166666620015298 par = [0.666666653134728, 0.8333333543416581]
Max h = 0.5 OF = 5.8333333916516725 par = [1.3333333485322296, -0.8333333510094758]
Min h = 1.0 OF = 3.333333291678896 par = [0.33333331979902153, 1.666666692683788]
Max h = 1.0 OF = 6.66666673165455 par = [1.6666666835343882, -1.666666686017392]
┌ Info: New seed: 2015
└ @ Mads /Users/vvv/.julia/dev/Mads/src/MadsHelpers.jl:462
Min h = 0.001 OF = 4.9960744454905965 par = [-0.03655198917957378, 1.0437989392240055, -0.008246956140052745]
Max h = 0.001 OF = 5.003925554522909 par = [0.036551989057392965, 0.9562010609257169, 0.008246956122525443]
Min h = 0.01 OF = 4.960745363330646 par = [-0.36551410869632334, 1.437982560318741, -0.08246845805988594]
Max h = 0.01 OF = 5.039254636799261 par = [0.3655141073877924, 0.5620174412841543, 0.08246845786044212]
Min h = 0.02 OF = 4.921490828175631 par = [-0.731027566617381, 1.8759643517308704, -0.16493679213714782]
Max h = 0.02 OF = 5.078509171873495 par = [0.7310275550438009, 0.12403566252037508, 0.1649367889027792]
Min h = 0.05 OF = 4.803727222947509 par = [-1.8275679184585027, 3.1899096986947266, -0.41234178651963727]
Max h = 0.05 OF = 5.196272777724391 par = [1.8275679123567241, -1.189909691219638, 0.41234178565241686]
Min h = 0.1 OF = 4.607454547104612 par = [-3.6551351873746936, 5.379818629776438, -0.8246834485881221]
Max h = 0.1 OF = 5.392545454245484 par = [3.655135175083979, -3.3798186147139266, 0.824683446810193]
Min h = 0.2 OF = 4.214909194737556 par = [-7.310269737140044, 9.759636506472651, -1.64936677598685]
Max h = 0.2 OF = 5.7850908074455605 par = [7.3102697046759735, -7.759636466764177, 1.6493667702921515]
Min h = 0.5 OF = 3.591684039656965 par = [-7.751158513274632, 10.000000041783382, -0.8850280664081923]
Max h = 0.5 OF = 6.49427721194079 par = [9.382981348214942, -10.000000044037646, 1.3871392608548654]
Min h = 1.0 OF = 2.6876583975888058 par = [-8.067223019985045, 10.000000062883482, 0.0672229701222594]
Max h = 1.0 OF = 7.44592953417183 par = [9.736303636511739, -10.000000065441785, 0.26369642586347747]
┌ Info: New seed: 2015
└ @ Mads /Users/vvv/.julia/dev/Mads/src/MadsHelpers.jl:462
Min h = 0.001 OF = 4.993999809993968 par = [-0.0001250040451789784, 1.0026250655869564, -0.0035000665302511625, 2.999997843315674]
Max h = 0.001 OF = 5.006000200041004 par = [0.00012500374313672267, 0.997374931285495, 0.0035000749793720805, 3.000000029507715]
Min h = 0.01 OF = 4.939999809729828 par = [-0.0012500039848518721, 1.0262500653481148, -0.03500006635146049, 2.999999811324717]
Max h = 0.01 OF = 5.060000190420172 par = [0.0012500039827685484, 0.9737499347289683, 0.035000066376460574, 2.9999998113247166]
Min h = 0.02 OF = 4.879999809436044 par = [-0.002500003917827296, 1.0525000650829668, -0.07000006615333457, 2.9999999206621957]
Max h = 0.02 OF = 5.120000190863952 par = [0.002500003913660588, 0.9474999350712004, 0.0700000662033339, 2.9999999206621952]
Min h = 0.05 OF = 4.699999809110879 par = [-0.006250003705588852, 1.1312500640011731, -0.17500006484468256, 2.9999999863618134]
Max h = 0.05 OF = 5.300000191636143 par = [0.006250003695269465, 0.8687499363840293, 0.1750000649694136, 2.99999998635084]
Min h = 0.1 OF = 4.399999807272094 par = [-0.012500003374736784, 1.2625000628015948, -0.35000006419023805, 3.000000008232852]
Max h = 0.1 OF = 5.600000194228184 par = [0.012500003353865882, 0.7374999379699614, 0.35000006443880427, 3.0000000082339633]
Min h = 0.2 OF = 3.7999998042537553 par = [-0.025000002708412933, 1.5250000602396283, -0.700000062415874, 3.000000019082813]
Max h = 0.2 OF = 6.20000019874704 par = [0.02500000266667985, 0.47499994130280493, 0.7000000629146885, 3.0000000190840956]
Min h = 0.5 OF = 1.999999795385952 par = [-0.06250000069969568, 2.3125000523306776, -1.7500000565793346, 3.000000025626925]
Max h = 0.5 OF = 8.000000212115324 par = [0.0625000005955181, -0.31250004847656593, 1.7500000578296342, 3.0000000256271333]
Min h = 1.0 OF = -1.0000002193334967 par = [-0.12499999734956149, 3.625000039098136, -3.5000000467297627, 3.000000027811915]
Max h = 1.0 OF = 11.000000234333372 par = [0.12499999714118018, -1.6250000313891586, 3.5000000492286207, 3.000000027812066]
┌ Info: New seed: 2015
└ @ Mads /Users/vvv/.julia/dev/Mads/src/MadsHelpers.jl:462
Min h = 0.001 OF = 4.93820509022155 par = [-1.991956463987334e-8, 1.001080524737567, -0.0020801343866858023, 2.9999999883894968]
Max h = 0.001 OF = 5.061794919720368 par = [1.991956366528757e-8, 0.9989194750922847, 0.002080134822476713, 3.000000029984543]
Min h = 0.01 OF = 4.382067676125225 par = [-1.9919025980225499e-7, 1.0108050472181263, -0.020801056118970217, 3.0000000258388377]
Max h = 0.01 OF = 5.617932323094888 par = [1.991902594702715e-7, 0.9891949528332155, 0.020801056167635203, 3.0000000258388377]
Min h = 0.02 OF = 3.7641372160181787 par = [-3.9837992109379617e-7, 1.0216100721965256, -0.0416020802659529, 3.0000000279194157]
Max h = 0.02 OF = 6.23586278242203 par = [3.983799204298235e-7, 0.9783899279061579, 0.041602080363282834, 3.0000000279194157]
Min h = 0.05 OF = 1.9103458356971257 par = [-9.959489049683935e-7, 1.0540251471317235, -0.10400515270690125, 3.0000000291677655]
Max h = 0.05 OF = 8.089654160403452 par = [9.959489033084791e-7, 0.945974853124985, 0.1040051529502259, 3.0000000291677655]
Min h = 0.1 OF = -1.1793064329087564 par = [-1.9918972144258892e-6, 1.1080502714651672, -0.20801027206863687, 3.000000028258382]
Max h = 0.1 OF = 11.179306457039136 par = [1.9918972081062344e-6, 0.8919497284896971, 0.2080102739284642, 3.0000000295838825]
Min h = 0.2 OF = -7.358611065908197 par = [-3.983793824341401e-6, 1.2161005218077126, -0.41602051491164094, 3.000000029791941]
Max h = 0.2 OF = 17.35861105031053 par = [3.98379381770175e-6, 0.7838994792191215, 0.41602051588494027, 3.000000029791941]
Min h = 0.5 OF = -25.896488521674833 par = [-9.959487073347952e-6, 1.5402506350898875, -1.0400496755102369, 2.999999728223722]
Max h = 0.5 OF = 35.896523990350396 par = [9.959483725387019e-6, 0.4597487460979546, 1.040051205638272, 3.000000022944347]
Min h = 1.0 OF = -56.79304787447036 par = [-1.9918966727663864e-5, 2.0805025200796528, -2.0801024466702493, 3.0000000299583918]
Max h = 1.0 OF = 66.79304780650143 par = [1.9918966693524435e-5, -0.08050251512076644, 2.080102451967674, 3.0000000299999843]</code></pre><pre><code class="language-julia hljs">Mads.display(&quot;infogap_opportuneness_vs_robustness.png&quot;)</code></pre><p><img src="model_diagnostics_files/model_diagnostics_86_0.png" alt="png"/></p><p>The figure above compares the model <code>opportuneness</code> (dashed lines) vs model <code>robustness</code> (solid lines) for different infogap horizons of uncertainty <code>h</code> and different models (different colors).</p><p>The model <code>opportuneness</code> defines that the things might get better than expected (i.e., observation at dimensionless time 5 <code>o5</code> can get lower than expected).</p><p>The model <code>robustness</code> defines that things might get worse than expected (i.e., observation at dimensionless time 5 <code>o5</code> can get higher than expected).</p><p>Based on both the model <code>opportuneness</code> and model <code>robustness</code>, the last model is the most complex and can bring the most surprises. The first model is the simplest and produces the lower level of surprises.</p><p>In terms of model selection, the simplest model is the best. However, the alternative models (if they capture all the conceptual model uncertainties) represent how much things can get worse/better within the horizon of uncertainty.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Examples.html">« Example Problems</a><a class="docs-footer-nextpage" href="../model_inversion_contamination/model_inversion_contamination.html">Model Calibration »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 2 May 2023 20:56">Tuesday 2 May 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
